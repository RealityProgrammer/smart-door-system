"use client";

import { useState, useRef, useEffect, useCallback, JSX } from "react";
import * as faceapi from "face-api.js";
import { Card, CardContent, CardHeader, CardTitle } from "@/components/ui/card";
import { Button } from "@/components/ui/button";
import {
  Select,
  SelectContent,
  SelectItem,
  SelectTrigger,
  SelectValue,
} from "@/components/ui/select";
import { Badge } from "@/components/ui/badge";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import {
  Camera,
  Lock,
  Unlock,
  UserPlus,
  Activity,
  Users,
  AlertCircle,
  Settings,
  Play,
  Pause,
  RotateCw,
  MessageSquare,
} from "lucide-react";
import { Alert, AlertDescription } from "@/components/ui/alert";
import { apiService } from "@/services/api";
import { useFaceManagement } from "@/hooks/useFaceManagement";
import {
  DetectedFace,
  DoorStatus,
  RecognitionStatus,
  SystemInfo,
  AutoRecognitionState,
  VARIATION_TYPES,
} from "@/types";

// Import c√°c components qu·∫£n l√Ω khu√¥n m·∫∑t
import { AddFaceDialog } from "@/components/FaceManagement/AddFaceDialog";
import { FaceList } from "@/components/FaceManagement/FaceList";
import { DoorStatus as DoorStatusComponent } from "@/components/Dashboard/DoorStatus";
import { RecognitionStatus as RecognitionStatusComponent } from "@/components/Dashboard/RecognotionStatus";
import { SystemInfo as SystemInfoComponent } from "@/components/Dashboard/SystemInfo";
import { VoiceInterface } from "@/components/VoiceChat/VoiceInterface";
import { CameraProvider, useCamera } from "@/contexts/CameraContext";

// Main component wrapped with camera context
function SmartDoorSystemContent(): JSX.Element | null {
  // Use shared camera context
  const {
    videoRef,
    canvasRef,
    isStreaming,
    cameras,
    selectedCamera,
    cameraError,
    modelsLoaded,
    startStream,
    stopStream,
    switchCamera,
    getCameras,
    captureImage,
    setModelsLoaded,
  } = useCamera();

  // Recognition states
  const [doorStatus, setDoorStatus] = useState<DoorStatus>("locked");
  const [recognitionStatus, setRecognitionStatus] =
    useState<RecognitionStatus>("idle");
  const [detectedFaces, setDetectedFaces] = useState<DetectedFace[]>([]);
  const [autoStartCamera, setAutoStartCamera] = useState(true);

  // Auto recognition states
  const [autoRecognition, setAutoRecognition] = useState<AutoRecognitionState>({
    isActive: false,
    attemptCount: 0,
    maxAttempts: 10,
    cooldownUntil: null,
    lastAttempt: 0,
  });

  // Refs to avoid stale state inside intervals
  const autoRecognitionRef = useRef(autoRecognition);
  const recognitionStatusRef = useRef(recognitionStatus);
  const detectedFacesRef = useRef(detectedFaces);
  const isStreamingRef = useRef(isStreaming);
  const modelsLoadedRef = useRef(modelsLoaded);
  const isRecognitionInFlightRef = useRef(false);

  // UI states
  const [isClient, setIsClient] = useState(false);
  const [activeTab, setActiveTab] = useState("camera");

  // Multi-variation capture states
  const [isCapturingVariations, setIsCapturingVariations] = useState(false);
  const [currentVariationIndex, setCurrentVariationIndex] = useState(0);
  const [capturedVariations, setCapturedVariations] = useState<string[]>([]);
  const [personNameForVariations, setPersonNameForVariations] =
    useState<string>("");

  const { isLoading, addFaceVariation, faces, fetchFaces } =
    useFaceManagement();

  const detectionIntervalRef = useRef<NodeJS.Timeout | null>(null);
  const autoRecognitionIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // Load faces khi component mount
  useEffect(() => {
    fetchFaces();
  }, [fetchFaces]);

  // Keep refs in sync
  useEffect(() => { autoRecognitionRef.current = autoRecognition; }, [autoRecognition]);
  useEffect(() => { recognitionStatusRef.current = recognitionStatus; }, [recognitionStatus]);
  useEffect(() => { detectedFacesRef.current = detectedFaces; }, [detectedFaces]);
  useEffect(() => { isStreamingRef.current = isStreaming; }, [isStreaming]);
  useEffect(() => { modelsLoadedRef.current = modelsLoaded; }, [modelsLoaded]);

  // Load face-api.js models
  useEffect(() => {
    const loadModels = async () => {
      try {
        await Promise.all([
          faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
          faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
          faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
          faceapi.nets.faceExpressionNet.loadFromUri("/models"),
        ]);
        setModelsLoaded(true);
        console.log("Face-api.js models loaded successfully");
      } catch (error) {
        console.error("Error loading face-api.js models:", error);
      }
    };

    if (isClient) {
      loadModels();
    }
  }, [isClient, setModelsLoaded]);

  // ƒê·∫£m b·∫£o component ch·ªâ render sau khi mount (client-side)
  useEffect(() => {
    setIsClient(true);
  }, []);

  // Auto-start camera when models loaded and cameras available
  useEffect(() => {
    if (
      isClient &&
      modelsLoaded &&
      cameras.length > 0 &&
      autoStartCamera &&
      !isStreaming
    ) {
      startStream();
    }
  }, [isClient, modelsLoaded, cameras.length, autoStartCamera, isStreaming, startStream]);

  // Face detection function
  const detectFaces = useCallback(async () => {
    if (
      !videoRef.current ||
      !canvasRef.current ||
      !modelsLoaded ||
      !isStreaming ||
      !videoRef.current.videoWidth ||
      !videoRef.current.videoHeight
    )
      return;

    try {
      // ƒê·∫£m b·∫£o video ƒë√£ load metadata
      if (videoRef.current.readyState < 2) {
        return; // Video ch∆∞a s·∫µn s√†ng
      }

      const detections = await faceapi
        .detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions())
        .withFaceLandmarks()
        .withFaceDescriptors();

      const canvas = canvasRef.current;
      const displaySize = {
        width: videoRef.current.videoWidth || 640,
        height: videoRef.current.videoHeight || 480,
      };

      faceapi.matchDimensions(canvas, displaySize);
      const resizedDetections = faceapi.resizeResults(detections, displaySize);

      // Clear canvas
      const ctx = canvas.getContext("2d");
      if (ctx) {
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        // Draw face boxes and landmarks
        faceapi.draw.drawDetections(canvas, resizedDetections);
        faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);

        // Draw custom face boxes with labels
        resizedDetections.forEach((detection, index) => {
          const box = detection.detection.box;
          ctx.strokeStyle = "#00ff00";
          ctx.lineWidth = 3;
          ctx.strokeRect(box.x, box.y, box.width, box.height);

          ctx.fillStyle = "#00ff00";
          ctx.font = "16px Arial";
          ctx.fillText(`Khu√¥n m·∫∑t ${index + 1}`, box.x, box.y - 5);
        });
      }

      setDetectedFaces(
        detections.map((d) => ({
          detection: d.detection,
          descriptor: d.descriptor,
        }))
      );
    } catch (error) {
      console.error("Error detecting faces:", error);
    }
  }, [modelsLoaded, isStreaming, videoRef, canvasRef]);

  // Start face detection interval
  useEffect(() => {
    if (isStreaming && modelsLoaded) {
      detectionIntervalRef.current = setInterval(detectFaces, 300);
    } else if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }

    return () => {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
      }
    };
  }, [isStreaming, modelsLoaded, detectFaces]);

  // Auto recognition logic
  const performAutoRecognition = async () => {
    const currentAuto = autoRecognitionRef.current;
    const currentStatus = recognitionStatusRef.current;
    const facesCount = detectedFacesRef.current.length;
    const nowStreaming = isStreamingRef.current;

    console.log("üîç Auto Recognition Check:", {
      isStreaming: nowStreaming,
      detectedFacesCount: facesCount,
      recognitionStatus: currentStatus,
      autoRecognitionActive: currentAuto.isActive,
      cooldownUntil: currentAuto.cooldownUntil,
      attemptCount: currentAuto.attemptCount,
      inFlight: isRecognitionInFlightRef.current,
      now: Date.now(),
    });

    if (
      !nowStreaming ||
      facesCount === 0 ||
      currentStatus === "scanning" ||
      isRecognitionInFlightRef.current
    ) {
      return;
    }

    const now = Date.now();

    // Ki·ªÉm tra cooldown
    if (currentAuto.cooldownUntil && now < currentAuto.cooldownUntil) {
      return;
    }

    // Ki·ªÉm tra s·ªë l·∫ßn th·ª≠
    if (currentAuto.attemptCount >= currentAuto.maxAttempts) {
      setAutoRecognition((prev) => ({
        ...prev,
        cooldownUntil: now + 30000,
        attemptCount: 0,
      }));
      return;
    }

    // Ki·ªÉm tra interval gi·ªØa c√°c l·∫ßn th·ª≠ (t·ªëi thi·ªÉu 2 gi√¢y)
    if (now - currentAuto.lastAttempt < 2000) {
      return;
    }

    console.log("‚úÖ Starting recognition...");
    isRecognitionInFlightRef.current = true;
    setRecognitionStatus("scanning");

    try {
      const imageBase64 = captureImage();
      if (!imageBase64) {
        throw new Error("Kh√¥ng th·ªÉ ch·ª•p ·∫£nh");
      }

      console.log("üîÑ Calling API...");
      const result = await apiService.recognizeFace(imageBase64);
      console.log("üì° API Response:", result);

      setAutoRecognition((prev) => ({
        ...prev,
        attemptCount: prev.attemptCount + 1,
        lastAttempt: now,
      }));
      autoRecognitionRef.current = {
        ...autoRecognitionRef.current,
        attemptCount: autoRecognitionRef.current.attemptCount + 1,
        lastAttempt: now,
      };

      if (result.success && result.result) {
        const {
          recognized,
          name,
          confidence,
          distance,
          threshold,
          best_variation,
          message,
        } = result.result;

        if (recognized) {
          setRecognitionStatus("recognized");
          setDoorStatus("unlocked");

          // Hi·ªÉn th·ªã notification nh·∫π nh√†ng
          const notification = document.createElement("div");
          notification.className =
            "fixed top-4 right-4 bg-green-500 text-white p-4 rounded-lg shadow-lg z-50";
          notification.innerHTML = `
            <div class="flex items-center gap-2">
              <div class="w-2 h-2 bg-white rounded-full"></div>
              <div>
                <div class="font-medium">Ch√†o m·ª´ng ${name}!</div>
                <div class="text-sm opacity-90">Variation: ${
                  best_variation || "default"
                }</div>
              </div>
            </div>
          `;
          document.body.appendChild(notification);

          setTimeout(() => {
            if (notification && notification.parentNode) {
              notification.parentNode.removeChild(notification);
            }
          }, 3000);

          // D·ª´ng auto recognition ngay khi nh·∫≠n di·ªán th√†nh c√¥ng
          stopAutoRecognition();

          setTimeout(() => {
            setDoorStatus("locked");
            setRecognitionStatus("idle");
          }, 5000);
          isRecognitionInFlightRef.current = false;
          return; // Tho√°t lu√¥n, kh√¥ng nh·∫≠n di·ªán n·ªØa
        } else {
          setRecognitionStatus("unknown");

          // Hi·ªÉn th·ªã c·∫£nh b√°o nh·∫π ch·ªâ khi h·∫øt attempts
          const latestAuto = autoRecognitionRef.current;
          if (latestAuto.attemptCount >= latestAuto.maxAttempts - 1) {
            const notification = document.createElement("div");
            notification.className =
              "fixed top-4 right-4 bg-yellow-500 text-white p-4 rounded-lg shadow-lg z-50";
            notification.innerHTML = `
              <div class="flex items-center gap-2">
                <div class="w-2 h-2 bg-white rounded-full animate-pulse"></div>
                <div>
                  <div class="font-medium">Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c</div>
                  <div class="text-sm opacity-90">Th·ª≠ l·∫°i sau 30 gi√¢y</div>
                </div>
              </div>
            `;
            document.body.appendChild(notification);

            setTimeout(() => {
              if (notification && notification.parentNode) {
                notification.parentNode.removeChild(notification);
              }
            }, 3000);
          }

          setTimeout(() => setRecognitionStatus("idle"), 1000);
        }
      }
    } catch (error) {
      console.error("Auto recognition error:", error);
      setRecognitionStatus("idle");
    }
    finally {
      isRecognitionInFlightRef.current = false;
    }
  };

  // Start auto recognition
  const startAutoRecognition = () => {
    setAutoRecognition((prev) => ({
      ...prev,
      isActive: true,
      attemptCount: 0,
      cooldownUntil: null,
    }));
  };

  // Stop auto recognition
  const stopAutoRecognition = () => {
    setAutoRecognition((prev) => ({
      ...prev,
      isActive: false,
      attemptCount: 0,
      cooldownUntil: null,
    }));
    if (autoRecognitionIntervalRef.current) {
      clearInterval(autoRecognitionIntervalRef.current);
      autoRecognitionIntervalRef.current = null;
    }
    isRecognitionInFlightRef.current = false;
  };

  // Auto recognition interval
  useEffect(() => {
    if (autoRecognition.isActive && isStreaming && modelsLoaded) {
      console.log("‚úÖ Setting up auto recognition interval");
      // Use a tighter control loop that respects in-flight guard
      const intervalId = setInterval(() => {
        if (!isRecognitionInFlightRef.current) {
          performAutoRecognition();
        }
      }, 1000);
      autoRecognitionIntervalRef.current = intervalId;
    } else {
      if (autoRecognitionIntervalRef.current) {
        console.log("‚ùå Clearing auto recognition interval");
        clearInterval(autoRecognitionIntervalRef.current);
        autoRecognitionIntervalRef.current = null;
      }
    }

    return () => {
      if (autoRecognitionIntervalRef.current) {
        clearInterval(autoRecognitionIntervalRef.current);
        autoRecognitionIntervalRef.current = null;
      }
    };
  }, [autoRecognition.isActive, isStreaming, modelsLoaded]);

  // Multi-variation capture logic
  const startMultiVariationCapture = (personName: string) => {
    setPersonNameForVariations(personName);
    setIsCapturingVariations(true);
    setCurrentVariationIndex(0);
    setCapturedVariations([]);
  };

  const captureNextVariation = async () => {
    if (currentVariationIndex >= VARIATION_TYPES.length) {
      finishMultiVariationCapture();
      return;
    }

    const currentVariationType = VARIATION_TYPES[currentVariationIndex];
    const imageBase64 = captureImage();

    if (!imageBase64) {
      alert("Kh√¥ng th·ªÉ ch·ª•p ·∫£nh! Vui l√≤ng ki·ªÉm tra camera.");
      return;
    }

    try {
      const success = await addFaceVariation(
        personNameForVariations,
        imageBase64,
        currentVariationType.value
      );

      if (success) {
        setCapturedVariations((prev) => [...prev, currentVariationType.value]);
        setCurrentVariationIndex((prev) => prev + 1);

        // Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n cho variation ti·∫øp theo
        if (currentVariationIndex + 1 < VARIATION_TYPES.length) {
          const nextVariation = VARIATION_TYPES[currentVariationIndex + 1];
          const notification = document.createElement("div");
          notification.className =
            "fixed top-4 left-1/2 transform -translate-x-1/2 bg-blue-500 text-white p-4 rounded-lg shadow-lg z-50 max-w-md";
          notification.innerHTML = `
            <div class="text-center">
              <div class="font-medium">‚úÖ ƒê√£ ch·ª•p: ${currentVariationType.label}</div>
              <div class="text-sm mt-2">Ti·∫øp theo: <strong>${nextVariation.label}</strong></div>
              <div class="text-xs opacity-90 mt-1">${nextVariation.description}</div>
            </div>
          `;
          document.body.appendChild(notification);

          setTimeout(() => {
            if (notification && notification.parentNode) {
              notification.parentNode.removeChild(notification);
            }
          }, 3000);
        }
      }
    } catch (error) {
      console.error("Error capturing variation:", error);
      alert("‚ùå L·ªói khi ch·ª•p variation: " + (error as Error).message);
    }
  };

  const finishMultiVariationCapture = async () => {
    setIsCapturingVariations(false);
    await fetchFaces();

    const notification = document.createElement("div");
    notification.className =
      "fixed top-4 left-1/2 transform -translate-x-1/2 bg-green-500 text-white p-4 rounded-lg shadow-lg z-50";
    notification.innerHTML = `
      <div class="text-center">
        <div class="font-medium">üéâ Ho√†n th√†nh!</div>
        <div class="text-sm">ƒê√£ ch·ª•p ${capturedVariations.length} variations cho ${personNameForVariations}</div>
      </div>
    `;
    document.body.appendChild(notification);

    setTimeout(() => {
      if (notification && notification.parentNode) {
        notification.parentNode.removeChild(notification);
      }
    }, 4000);

    // Reset states
    setPersonNameForVariations("");
    setCurrentVariationIndex(0);
    setCapturedVariations([]);
  };

  // X·ª≠ l√Ω th√™m khu√¥n m·∫∑t v·ªõi variation
  const handleAddFaceVariation = async (
    name: string,
    variationType: string
  ): Promise<void> => {
    const imageBase64 = captureImage();
    if (!imageBase64) {
      alert("Kh√¥ng th·ªÉ ch·ª•p ·∫£nh! Vui l√≤ng ki·ªÉm tra camera.");
      return;
    }

    try {
      const success = await addFaceVariation(name, imageBase64, variationType);
      if (success) {
        // Ki·ªÉm tra n·∫øu l√† ng∆∞·ªùi m·ªõi v√† variation l√† default
        const isNewPerson = !faces.some((face) => face.name === name);
        const isDefaultVariation = variationType === "default";

        if (isNewPerson && isDefaultVariation) {
          // H·ªèi c√≥ mu·ªën ch·ª•p t·∫•t c·∫£ variations kh√¥ng
          const shouldCaptureAll = confirm(
            `‚úÖ ƒê√£ th√™m "${name}" th√†nh c√¥ng!\n\n` +
              `üéØ ƒê·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c nh·∫≠n di·ªán, h·ªá th·ªëng khuy·∫øn kh√≠ch ch·ª•p th√™m ${
                VARIATION_TYPES.length - 1
              } variations kh√°c.\n\n` +
              `B·∫°n c√≥ mu·ªën ti·∫øp t·ª•c ch·ª•p t·∫•t c·∫£ variations ngay b√¢y gi·ªù kh√¥ng?\n\n` +
              `(B·∫°n c√≥ th·ªÉ b·ªè qua v√† th√™m sau)`
          );

          if (shouldCaptureAll) {
            startMultiVariationCapture(name);
            return;
          }
        }

        alert(`‚úÖ ƒê√£ th√™m variation "${variationType}" cho ${name}!`);
        await fetchFaces();
      }
    } catch (error) {
      console.error("Add variation error:", error);
      alert("‚ùå L·ªói khi th√™m variation: " + (error as Error).message);
    }
  };

  // Cleanup khi component unmount
  useEffect(() => {
    return () => {
      if (detectionIntervalRef.current) {
        clearInterval(detectionIntervalRef.current);
      }
      if (autoRecognitionIntervalRef.current) {
        clearInterval(autoRecognitionIntervalRef.current);
      }
    };
  }, []);

  // Kh√¥ng render g√¨ n·∫øu ch∆∞a mount (tr√°nh hydration mismatch)
  if (!isClient) {
    return null;
  }

  // Create systemInfo object
  const systemInfo: SystemInfo = {
    camerasAvailable: cameras.length,
    facesDetected: detectedFaces.length,
    modelsLoaded,
    totalFaces: faces.length,
  };

  // T√≠nh to√°n tr·∫°ng th√°i cooldown
  const cooldownRemaining = autoRecognition.cooldownUntil
    ? Math.max(
        0,
        Math.ceil((autoRecognition.cooldownUntil - Date.now()) / 1000)
      )
    : 0;

  return (
    <div className="min-h-screen bg-gradient-to-br from-blue-50 to-indigo-100 p-4">
      <div className="max-w-7xl mx-auto">
        <header className="text-center mb-8">
          <h1 className="text-4xl font-bold text-gray-800 mb-2">
            Smart Door System
          </h1>
          <p className="text-gray-600">
            H·ªá th·ªëng c·ª≠a th√¥ng minh v·ªõi nh·∫≠n di·ªán khu√¥n m·∫∑t AI
          </p>
        </header>

        {/* Error Alert */}
        {cameraError && (
          <Alert className="mb-6 border-red-200 bg-red-50">
            <AlertCircle className="h-4 w-4 text-red-600" />
            <AlertDescription className="text-red-700">
              {cameraError}
            </AlertDescription>
          </Alert>
        )}

        {/* Multi-variation capture overlay */}
        {isCapturingVariations && (
          <div className="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50">
            <Card className="w-full max-w-md mx-4">
              <CardHeader>
                <CardTitle className="text-center">
                  Ch·ª•p Variations cho {personNameForVariations}
                </CardTitle>
              </CardHeader>
              <CardContent className="space-y-4">
                <div className="text-center">
                  <div className="text-2xl font-bold text-blue-600">
                    {currentVariationIndex + 1} / {VARIATION_TYPES.length}
                  </div>
                  <div className="text-sm text-gray-600">
                    Progress:{" "}
                    {Math.round(
                      (currentVariationIndex / VARIATION_TYPES.length) * 100
                    )}
                    %
                  </div>
                </div>

                {currentVariationIndex < VARIATION_TYPES.length && (
                  <div className="text-center space-y-2">
                    <h3 className="text-lg font-medium">
                      {VARIATION_TYPES[currentVariationIndex].label}
                    </h3>
                    <p className="text-sm text-gray-600">
                      {VARIATION_TYPES[currentVariationIndex].description}
                    </p>
                  </div>
                )}

                <div className="flex gap-2">
                  <Button
                    onClick={captureNextVariation}
                    disabled={!isStreaming || detectedFaces.length === 0}
                    className="flex-1"
                  >
                    {currentVariationIndex >= VARIATION_TYPES.length
                      ? "Ho√†n th√†nh"
                      : "Ch·ª•p"}
                  </Button>
                  <Button
                    variant="outline"
                    onClick={finishMultiVariationCapture}
                  >
                    B·ªè qua
                  </Button>
                </div>

                {capturedVariations.length > 0 && (
                  <div className="text-xs text-gray-600">
                    ƒê√£ ch·ª•p: {capturedVariations.join(", ")}
                  </div>
                )}
              </CardContent>
            </Card>
          </div>
        )}

        {/* Main Tabs */}
        <Tabs value={activeTab} onValueChange={setActiveTab} className="w-full">
          <TabsList className="grid w-full grid-cols-4">
            <TabsTrigger value="camera" className="flex items-center gap-2">
              <Camera className="h-4 w-4" />
              Camera & Nh·∫≠n di·ªán
            </TabsTrigger>
            <TabsTrigger value="management" className="flex items-center gap-2">
              <Users className="h-4 w-4" />
              Qu·∫£n l√Ω khu√¥n m·∫∑t
            </TabsTrigger>
            <TabsTrigger value="voice" className="flex items-center gap-2">
              <MessageSquare className="h-4 w-4" />
              Tr·ª£ l√Ω gi·ªçng n√≥i
            </TabsTrigger>
            <TabsTrigger value="dashboard" className="flex items-center gap-2">
              <Settings className="h-4 w-4" />
              Dashboard
            </TabsTrigger>
          </TabsList>

          {/* Camera Tab */}
          <TabsContent value="camera" className="mt-6">
            <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
              {/* Video Stream */}
              <div className="lg:col-span-2">
                <Card>
                  <CardHeader>
                    <CardTitle className="flex items-center gap-2">
                      <Camera className="h-5 w-5" />
                      Camera Feed
                      {modelsLoaded && (
                        <Badge variant="outline">AI Ready</Badge>
                      )}
                      {autoRecognition.isActive && (
                        <Badge variant="secondary">
                          Auto Recognition {autoRecognition.attemptCount}/
                          {autoRecognition.maxAttempts}
                        </Badge>
                      )}
                      {cooldownRemaining > 0 && (
                        <Badge variant="destructive">
                          Cooldown: {cooldownRemaining}s
                        </Badge>
                      )}
                    </CardTitle>
                  </CardHeader>
                  <CardContent>
                    <div className="space-y-4">
                      {/* Camera Controls */}
                      <div className="flex gap-2 items-center flex-wrap">
                        <Select
                          value={selectedCamera}
                          onValueChange={switchCamera}
                          disabled={cameras.length === 0}
                        >
                          <SelectTrigger className="w-full max-w-xs">
                            <SelectValue placeholder="Ch·ªçn camera" />
                          </SelectTrigger>
                          <SelectContent>
                            {cameras.map((camera) => (
                              <SelectItem
                                key={camera.deviceId}
                                value={camera.deviceId}
                              >
                                {camera.label}
                              </SelectItem>
                            ))}
                          </SelectContent>
                        </Select>

                        <Button
                          onClick={isStreaming ? stopStream : startStream}
                          variant={isStreaming ? "destructive" : "default"}
                          disabled={cameras.length === 0 && !cameraError}
                        >
                          {isStreaming ? (
                            <>
                              <Pause className="h-4 w-4 mr-2" />
                              D·ª´ng
                            </>
                          ) : (
                            <>
                              <Play className="h-4 w-4 mr-2" />
                              B·∫Øt ƒë·∫ßu
                            </>
                          )}
                        </Button>

                        <Button
                          onClick={getCameras}
                          variant="outline"
                          size="sm"
                        >
                          <RotateCw className="h-4 w-4 mr-1" />
                          Refresh
                        </Button>

                        <div className="flex items-center gap-2">
                          <input
                            type="checkbox"
                            id="autoStart"
                            checked={autoStartCamera}
                            onChange={(e) =>
                              setAutoStartCamera(e.target.checked)
                            }
                          />
                          <label htmlFor="autoStart" className="text-sm">
                            Auto-start camera
                          </label>
                        </div>
                      </div>

                      {/* Video Display v·ªõi Face Detection Overlay */}
                      <div className="relative aspect-video bg-gray-900 rounded-lg overflow-hidden">
                        <video
                          ref={videoRef}
                          className="w-full h-full object-cover"
                          playsInline
                          muted
                          style={{ transform: "scaleX(-1)" }}
                        />
                        <canvas
                          ref={canvasRef}
                          className="absolute inset-0 w-full h-full"
                          style={{ transform: "scaleX(-1)" }}
                        />

                        {!isStreaming && (
                          <div className="absolute inset-0 flex items-center justify-center text-white">
                            <div className="text-center">
                              <Camera className="h-12 w-12 mx-auto mb-2 opacity-50" />
                              <p>
                                {cameras.length === 0 && !cameraError
                                  ? "ƒêang t·∫£i camera..."
                                  : "Camera ch∆∞a ƒë∆∞·ª£c b·∫≠t"}
                              </p>
                            </div>
                          </div>
                        )}

                        {recognitionStatus === "scanning" && (
                          <div className="absolute inset-0 bg-blue-500 bg-opacity-20 flex items-center justify-center">
                            <div className="bg-white rounded-lg p-4 shadow-lg">
                              <div className="animate-spin h-8 w-8 border-4 border-blue-500 border-t-transparent rounded-full mx-auto mb-2"></div>
                              <p className="text-blue-700 font-medium">
                                {autoRecognition.isActive
                                  ? "ƒêang qu√©t t·ª± ƒë·ªông..."
                                  : "ƒêang nh·∫≠n di·ªán..."}
                              </p>
                            </div>
                          </div>
                        )}

                        {/* Face Detection Status */}
                        {isStreaming && (
                          <div className="absolute top-4 left-4">
                            <Badge
                              variant={
                                detectedFaces.length > 0
                                  ? "default"
                                  : "secondary"
                              }
                            >
                              Ph√°t hi·ªán: {detectedFaces.length} khu√¥n m·∫∑t
                            </Badge>
                          </div>
                        )}
                      </div>

                      {/* Control Buttons */}
                      <div className="flex gap-2 flex-wrap">
                        <Button
                          onClick={() => {
                            console.log("üéØ Auto Recognition Button Clicked:", {
                              currentState: autoRecognition.isActive,
                              isStreaming,
                              modelsLoaded,
                            });

                            if (autoRecognition.isActive) {
                              stopAutoRecognition();
                            } else {
                              startAutoRecognition();
                            }
                          }}
                          disabled={!isStreaming || modelsLoaded === false}
                          variant={
                            autoRecognition.isActive ? "destructive" : "default"
                          }
                          className="flex-1 min-w-0"
                        >
                          {autoRecognition.isActive ? (
                            <>
                              <Pause className="h-4 w-4 mr-2" />
                              D·ª´ng nh·∫≠n di·ªán t·ª± ƒë·ªông
                            </>
                          ) : (
                            <>
                              <Play className="h-4 w-4 mr-2" />
                              B·∫Øt ƒë·∫ßu nh·∫≠n di·ªán t·ª± ƒë·ªông
                            </>
                          )}
                        </Button>
                        {/* N√∫t Nh·∫≠n di·ªán l·∫°i */}
                        <Button
                          onClick={startAutoRecognition}
                          disabled={!isStreaming || autoRecognition.isActive}
                          variant="outline"
                          className="flex-1 min-w-0"
                        >
                          <Activity className="h-4 w-4 mr-2" />
                          Nh·∫≠n di·ªán l·∫°i
                        </Button>
                        <AddFaceDialog
                          onCapture={handleAddFaceVariation}
                          isLoading={isLoading}
                        />
                      </div>

                      {/* Auto Recognition Info */}
                      {isStreaming && (
                        <div className="text-xs text-gray-600 bg-gray-50 p-3 rounded">
                          <div className="grid grid-cols-2 gap-2">
                            <div>
                              Status:{" "}
                              {autoRecognition.isActive
                                ? "üü¢ Active"
                                : "üî¥ Inactive"}
                            </div>
                            <div>
                              Attempts: {autoRecognition.attemptCount}/
                              {autoRecognition.maxAttempts}
                            </div>
                            <div>Faces: {detectedFaces.length}</div>
                            <div>
                              {cooldownRemaining > 0
                                ? `Cooldown: ${cooldownRemaining}s`
                                : "Ready"}
                            </div>
                          </div>
                        </div>
                      )}
                    </div>
                  </CardContent>
                </Card>
              </div>

              {/* Status Panel */}
              <div className="space-y-6">
                <DoorStatusComponent status={doorStatus} />
                <RecognitionStatusComponent status={recognitionStatus} />
                <SystemInfoComponent systemInfo={systemInfo} />
              </div>
            </div>
          </TabsContent>

          {/* Face Management Tab */}
          <TabsContent value="management" className="mt-6">
            <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
              {/* Add Face Section */}
              <Card>
                <CardHeader>
                  <CardTitle className="flex items-center gap-2">
                    <UserPlus className="h-5 w-5" />
                    Th√™m khu√¥n m·∫∑t m·ªõi
                  </CardTitle>
                </CardHeader>
                <CardContent>
                  <div className="space-y-4">
                    <p className="text-sm text-gray-600">
                      Camera ƒëang ƒë∆∞·ª£c chia s·∫ª v·ªõi t·∫•t c·∫£ c√°c tab. B·∫°n c√≥ th·ªÉ th√™m khu√¥n m·∫∑t t·ª´ b·∫•t k·ª≥ tab n√†o.
                    </p>
                    <AddFaceDialog
                      onCapture={handleAddFaceVariation}
                      isLoading={isLoading}
                    />

                    {/* H∆∞·ªõng d·∫´n */}
                    <div className="text-sm text-gray-600 bg-blue-50 p-3 rounded">
                      <h4 className="font-medium mb-2">üí° H∆∞·ªõng d·∫´n t·ªëi ∆∞u:</h4>
                      <ul className="space-y-1 text-xs">
                        <li>
                          ‚Ä¢ <strong>Ng∆∞·ªùi m·ªõi:</strong> H·ªá th·ªëng s·∫Ω t·ª± ƒë·ªông
                          h∆∞·ªõng d·∫´n ch·ª•p t·∫•t c·∫£ variations
                        </li>
                        <li>
                          ‚Ä¢ <strong>Variations c√≥ s·∫µn:</strong>{" "}
                          {VARIATION_TYPES.map((v) => v.label).join(", ")}
                        </li>
                        <li>
                          ‚Ä¢ <strong>Ch·∫•t l∆∞·ª£ng ·∫£nh:</strong> R√µ n√©t, ƒë·ªß s√°ng,
                          khu√¥n m·∫∑t th·∫≥ng
                        </li>
                        <li>
                          ‚Ä¢ <strong>Nh·∫≠n di·ªán t·ª± ƒë·ªông:</strong> Ho·∫°t ƒë·ªông 24/7
                          v·ªõi limit 10 l·∫ßn/30s
                        </li>
                      </ul>
                    </div>
                  </div>
                </CardContent>
              </Card>

              {/* Face List */}
              <FaceList onDeleteSuccess={fetchFaces} />
            </div>
          </TabsContent>

          {/* Voice Assistant Tab - Now using shared camera */}
          <TabsContent value="voice" className="mt-6">
            <VoiceInterface />
          </TabsContent>

          {/* Dashboard Tab */}
          <TabsContent value="dashboard" className="mt-6">
            <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
              <DoorStatusComponent status={doorStatus} />
              <RecognitionStatusComponent status={recognitionStatus} />
              <SystemInfoComponent systemInfo={systemInfo} />

              {/* Statistics Card */}
              <Card>
                <CardHeader>
                  <CardTitle>Th·ªëng k√™</CardTitle>
                </CardHeader>
                <CardContent className="space-y-2">
                  <div className="flex justify-between">
                    <span>T·ªïng s·ªë ng∆∞·ªùi:</span>
                    <Badge variant="outline">{faces.length}</Badge>
                  </div>
                  <div className="flex justify-between">
                    <span>T·ªïng variations:</span>
                    <Badge variant="outline">
                      {faces.reduce(
                        (total, face) => total + (face.total_variations || 1),
                        0
                      )}
                    </Badge>
                  </div>
                  <div className="flex justify-between">
                    <span>L·∫ßn nh·∫≠n di·ªán:</span>
                    <Badge variant="outline">
                      {faces.reduce(
                        (total, face) => total + (face.recognition_count || 0),
                        0
                      )}
                    </Badge>
                  </div>
                  <div className="flex justify-between">
                    <span>Auto Recognition:</span>
                    <Badge
                      variant={
                        autoRecognition.isActive ? "default" : "secondary"
                      }
                    >
                      {autoRecognition.isActive ? "Active" : "Inactive"}
                    </Badge>
                  </div>
                </CardContent>
              </Card>
            </div>
          </TabsContent>
        </Tabs>
      </div>
    </div>
  );
}

// Main export v·ªõi CameraProvider wrapper
export default function SmartDoorSystem() {
  return (
    <CameraProvider>
      <SmartDoorSystemContent />
    </CameraProvider>
  );
}